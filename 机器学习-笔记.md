# 一、引言



基本情况：

1. 人工智能

   > 能够像人一样，**感知**外在的事务，并通过**自主的思维过程**做出有目的、有意义的**响应**。
   >
   > 总的来说，人工智能包含3个方面：
   >
   > - 感知
   > - 决策
   > - 行动

2. 模式识别

   > 是实现人工智能的一种**工具**，也就是要让机器知道它们处理的是什么。解决识别问题，侧重各层面的识别部分
   >
   > 狭义讲，模式识别是一种**任务**。

3. 机器学习

   > 是贯穿整个智能系统从**感知到决策到行动**的控制。
   >
   > 狭义讲，机器学习是一种通用工具，是目前模式识别使用最多的工具。



**人工智能**的发展经历了**两个阶段**

1. 逻辑推理，知识库与专家系统

   > 1980年，之前-逻辑推理，，人工建立规则、知识库

2. 机器学习

   > 1980年，之后-模仿人的学习能力，从案例中进行学习获得经验和知识



**机器学习**的发展经历了**三个阶段**：

1. 1980-1990年

   > 成为**独立**的学科，诞生了**决策树、反向传播算法、卷积神经网络**等经典算法

2. 1991-2011年

   > 蓬勃**发展**期，出现了大量方法，2次图灵奖。经典算法包括**支持向量机，随机森林，Boosting，RNN/LSTM流形学习，各种聚类**算法。

3. 2012年-至今

   > **深度学习**时代，**深度卷积神经网络，深度RNN，深度强化学习，深度生成模型，图神经网络，自动化机器学习**。







# 二、基础知识



## 2.1 机器学习定义



> 对于 **某类任务T** 和 **性能度量P**，一个计算机程序能从 **经验E** 中学习是指，
>
> 经过 **经验E** 的改进后，它在 **任务T** 上由 **性能度量P** 所衡量的性能有所提高。（Mitchell,1997）



> Machine learning as a set of methods that can automatically detect patterns in data, and then use the uncovered patterns to predict future data, or to perform other kinds of decision making under uncertainly. (Murphy, 2012)



## 2.2 具备学习能力的系统的基本流程

```mermaid
graph LR

collect[数据收集]
app[模型应用]
preprocess[数据预处理]
model[模型选择]
ml[模型学习]

collect--->preprocess
preprocess--->model
model--->ml
ml--->app
app--->collect
```

## 2.3 在线学习和离线学习

1. 在线学习（Online Learning）

   > 指的是在数据不断到来的过程中，动态地更新模型。在线算法按照顺序处理数据。
   >
   > 它们产生一个模型，并再把这个模型放入实际操作中，而不需要在一开始就提供完整的的训练数据集。

2. 在离线学习（Offline Learning）中

   > 指的是在离线状态下，使用历史数据进行学习，从而生成模型。所有的训练数据在模型训练期间必须是可用的。只有训练完成了之后，模型才能被拿来用。简而言之，先训练，再用模型，不训练完就不用模型。



## 2.4 ML主要类型

1. 监督学习
     - 分类
     - 回归
     - 排序
2. 无监督学习
     - 聚类算法
     - 流形学习
     - 自监督

3. 弱监督学习
   - 半监督

4. 强化学习

5. 数据生成



## 2.5 无监督学习



### 2.5.1 密度估计

Density estimation（密度估计）：

是根据一组训练样本来估计样本空间的概率密度。

密度估计可以分为：**参数密度估计**和**非参数密度估计**。

1. 参数密度估计

   > 是假设**数据服从某个已知概率密度函数形式的分布**，然后根据训练样本去估计该分布的参数。

2. 非参数密度估计

   > 是不假设服从某个概率分布，只利用训练样本对密度进行估计，可以进行任意形状的密度估计
   >
   > 非参数密度估计的方法包括：直方图、核密度估计等。

### 2.5.2 主成分分析

PCA(Principal Component Analysis)，即主成分分析方法，是一种使用最广泛的**数据降维算法**。

PCA的主要思想是**将n维特征映射到k维**上，这k维是全新的正交特征也被称为**主成分**，是在原有**n维特征**的基础上重新构造出来的**k维特征**。



### 2.5.3 自监督

自监督（Self-Supervised Learning）:

1. in a task-agnostic way

   > 第一个阶段不涉及任何下游任务，通过一堆无标签的数据去预训练，没有特定的任务，即：in a task-agnostic way。

2.  in a task-specific way

   > 第二个阶段涉及下游任务，通过一堆带标签的数据在下游任务上Fine-tune，即 in a task-specific way

<img src="assets/image-20231220182855121.png" alt="image-20231220182855121" style="zoom: 67%;" />



## 2.6 弱监督学习

- 不完全监督

  > 是指，训练数据中只有一部分数据被给了标签，有一些数据是没有标签的。

- 不确切监督

  > 是指，训练数据只给出了粗粒度标签。我们可以把输入想象成一个包，这个包里面有一些示例，我们只知道这个包的标签，Y或N，
  >
  > 但是我们不知道每个示例的标签

- 不精确监督

  > 是指，给出的标签不总是正确的，比如本来应该是Y的标签被错误标记成了N。



## 2.7 强化学习

**强化学习（Reinforcement learning，RL）**讨论的问题是一个智能体(agent) 怎么在一个复杂不确定的 环境(environment) 里面去极大化它能获得的奖励。

通过感知所处环境的 **状态(state)** 对 **动作(action)** 的 **反应(reward)**， 来指导更好的动作，从而获得最大的 **收益(return)**，

这被称为在交互中学习，这样的学习方法就被称作强化学习。



## 2.8 机器学习基本要素

1. 特定的数据集

   > 从数据学习
   >
   > 
   >
   > 示例1：手写数字识别MNIST数据集
   >
   > MNIST数据集来自美国国家标准与技术研究所, National Institute of Standards and Technology (NIST)。
   >
   > 训练集（training set）由来自250个不同人手写的数字构成，其中50%是高中学生，50%来自人口普查局（the Census Bureau）的工作人员。
   >
   > 测试集（test set）也是同样比例的手写数字数据，但保证了测试集和训练集的作者集不相交。
   >
   > MNIST数据集一共有7万张图片，其中6万张是训练集，1万张是测试集。每张图片是28 × 28 的0−9的手写数字图片组成。
   >
   > 每个图片是黑底白字的形式，黑底用0表示，白字用0-1之间的浮点数表示，越接近1，颜色越白。
   >
   > 
   >
   > 示例2：CIFAR-10数据集
   >
   > CIFAR-10 是一个包含60000张图片的数据集。其中每张照片为32*32的彩色照片，每个像素点包括RGB三个数值，数值范围0 ~ 255。
   >
   > 照片分属10个不同的类别，分别是 'airplane', 'automobile','bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'
   >
   > 其中五万张图片被划分为训练集，剩下的一万张图片属于测试集
   >
   > 

2. 目标函数（评价函数、风险函数）

   > 一个函数用于刻画系统对于目标的达成度，即要有一个目标函数（评价函数）
   >
   > -  风险函数
   >
   >    > 一种是评价它与目标系统的差距，称为为损失函数或者风险函数；
   >
   > -  收益函数
   >
   >    > —另一种是评价系统的收益
   >
   > -  经验风险函数
   >
   
3. 模型

   > 不同类型、层次的各种模型：
   >
   > 线性模型、非线性模型、参数模型、神经网络、深度神经网络

4. 优化算法

   > 优化过程





### 2.8.1 目标函数

目标函数通常用以下的公式来表示：**最优化经验风险 + 结构风险**

$Objective=\frac{1}{N}\sum\limits_{i=1}^{N}L(y_i,f(x_i))+\lambda{J(f)}$



$L(y_i,f(x_i))$ 是训练误差（经验风险），衡量模型在训练集上的表现

$J(f)$ 是正则项（结构风险），衡量模型的复杂度--约束项

$\lambda$ 是超参数，需要交叉验证来确定



1. **损失函数**

     一个函数来度量 **拟合的程度**，这就损失函数（loss function）,或者叫代价函数（cost function）,例如：$L(Y,f(x))=(Y-f(x))^2$

2. **经验风险函数**

   > 风险函数是损失函数的**期望**
   >
   > $f(x)$关于训练集的**平均损失称为经验风险（empirical risk）**，即$\frac{1}{N}\sum\limits_{i=1}^{N}L(y_i,f(x_i))$
   >
   > 所以我们的目标就是最小化这个函数,称为**经验风险最小化**

3. **结构风险和正则化**

     <img src="assets/image-20231220195752779.png" alt="image-20231220195752779" style="zoom: 80%;" />

     - 最右面的$f_3(x)$的经验风险函数最小,但是从图上来看$f_3(x)$肯定不是最好的，因为它过度学习历史数据，导致它在真正预测时效果会很不好，这种情况称为**过拟合(Overfitting)**。
     - 定义了一个函数$J(x)$ ，专门用来**度量模型的复杂度**，在机器学习中也叫**正则化(regularization)**，常用的有$L_1,L_2$范数。
     - 最左面的$f_1(x)$ 结构风险最小（模型结构最简单），但是经验风险最大（对历史数据拟合的最差）；最右面的$f_3(x)$ 经验风险最小（对历史数据拟合的最好），但是结构风险最大（模型结构最复杂）；而$f_2(x)$达到了二者的良好平衡，最适合用来预测未知数据集



### 2.8.2 训练与泛化

模型对训练集数据的误差称为**经验误差**，对测试集数据的误差称为**泛化误差**。模型对训练集以外样本的预测能力就称为模型的**泛化能力**，追求这种泛化能力始终是机器学习的目标

 

**泛化能力定义：**

1. 百度百科一

   > 是指**机器学习算法对新鲜样本的适应能力**。

2. 百度百科二

   > 原有的数据集上添加新的数据集，通过训练输出一个合理的结果。学习的目的是学到隐含在数据背后的规律，对具有同一规律的学习集以外的数据，经过训练的网络也能给出合适的输出，该能力称为泛化能力。



由于𝑝𝑑𝑎𝑡𝑎实际中未知，ML的训练是以经验风险最小替代风险最小。

经验风险最小若推知风险最小，称为泛化能力强。

实际中，经验风险优化可能带来过拟合问题，使得泛化性能差。

**经验风险结合正则化**等技术进行优化，可提升泛化能力。



**欠拟合（Underfitting）**，模型过于简单无法表达数据中复杂的变化规律，对训练样本都
无法得到好的拟合，也谈不上有好的泛化。

**过拟合(Overfitting)** ，模型训练误差达到很理想的结果，但是泛化性能差



正则化的基本做法是**对目标函数增加一个约束项，用于控制系统的复杂度**。



### 2.8.3 模型

**模型**：指的是一个机器学习的算法采用的具体数据表示形式，即 $y=h(x)$数学函数的具体化。

1. **参数模型**：
   - **定义**：参数模型假设数据的分布属于一个特定的参数化族。换句话说，模型的结构是事先定义好的，但是模型的参数是需要从数据中学习得到的。
   - **例子**：线性模型、非线性模型、逻辑回归、简单神经网络、（若固定了隐层的数目以及每一层神经元的个数），这些模型的结构已经确定，但是其中的参数（例如回归系数、均值、方差等）是通过训练数据估计得到的。
2. **非参数模型**
   - **定义：** 非参数模型在建模时对数据分布的形状没有明确的假设，模型的复杂性通常随着数据量的增加而增加。这种模型通常更加灵活，能够适应不同形状的数据分布。
   - **例子**：核密度估计、K近邻算法、SVM、决策树、朴素贝叶斯、复杂神经网络等可以被视为非参数模型。这些模型没有固定的参数数量，其复杂性和灵活性取决于训练数据的特征。



### 2.8.4 正则化

**正则化（Regularize）**：机器学习中经常会在损失函数中加入正则项，称之为正则化。

1. **目的：**防止模型过拟合，正则化可以看做是损失函数的惩罚项
2. **原理：**在损失函数上加上某些规则（限制），缩小解空间，从而减少求出拟合解的可能性
3. 常用正则项一般有两种，一般英文称做L1正则化和L2正则化，或L1范数和L2范数。



### 2.8.5 过拟合

避免模型过拟合的方法，总结大概以下几点：

1. 重新清洗数据（删除稀疏特征、对噪声数据进行处理（删除/替换））
2. 重新采样（改变采样方法等）
3.  增加训练数据
4.  采用交叉验证训练模型
5.  重新筛选特征
6.  降低模型复杂度（增加正则项：L1，L2）
7.  dropout（神经网络中，让神经元一定的概率不工作）



## 2.9 机器学习算法评价



### 2.9.1 数据集的划分

 机器学习算法的性能指标用于衡量算法的优劣，指导我们对模型进行选择与优化

不同类型的算法有不同的评价指标

 有监督学习有**训练与预测**两个阶段，通常用与训练样本集不同的另一个样本集统计算法的精度

​	①对于有监督学习，通常将样本集分为训练集，验证集，测试集3个不相交的子集

​	②训练集用于模型训练得到模型的参数，验证集用于确定算法的超参数，测试集则用于测试模型的精度

无监督学习需要直接用测试集，对算法的精度进行评估

在整个过程中，测试集不参与学习才能保证模型的泛化能力



**交叉验证技术：** *k*折交叉验证（*k*-fold cross-validation）：将样本集均匀的分成𝑘份，轮流用其中的𝑘−1份作为训练集，剩下的1份作为测试集，统计算法的精度用𝑘次统计的精的均值作为最后的精度值
$$
\frac{精度1+精度2+精度3+精度4}{4}
$$


![image-20231220212531903](assets/image-20231220212531903.png)



### 2.9.2 模型性能评估

**有监督学习的回归和分类的性能评估**：

机器学习模型 $y=h(x)$  进行性能评估，实际实在样本集进行



#### 2.9.2.1 回归的性能评估

模型 $y=h(x)$  的输出和标注均为实数，通常用**回归误差**作为指标：一般预测值与真实标签值的均方误差 
$$
E_{MES}=\frac{1}{N}\sum_{i=1}^{N}{(h(x_i)-y_i)^2}
$$
有时也用**平均绝对误差**：
$$
E_{MES}=\frac{1}{N}\sum_{i=1}^{N}{|h(x_i)-y_i|}
$$
或**最大误差**：
$$
E_{\infin}=\max \limits_{1<i<N}\{|h(x_i)-y_i|\}
$$

#### 2.9.2.2 分类的性能评估

评价分类的最基本的准则是分类的**错误率**和分类的**准确率**

1. 分类错误率
   $$
   E=\frac{1}{N}\sum_{i=1}^{N}{I(h(x_i)\neq y_i)}
   $$

2. 分类正确率
   $$
   Acc=1-E=\frac{1}{N}\sum_{i=1}^{N}{I(h(x_i)= y_i)}
   $$
   





# 三、回归分析

# 四、分类算法

# 五、人工神经网络

# 六、强化学习